{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb2405c1",
   "metadata": {},
   "source": [
    "# FOOD-101-MINI Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e431aa",
   "metadata": {},
   "source": [
    "### Autor: Filip Gębala"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd764969",
   "metadata": {},
   "source": [
    "#### Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbeb239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7521ef8c",
   "metadata": {},
   "source": [
    "#### Wczytywanie i przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63801311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder('Data/food-101-tiny/train', transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder('Data/food-101-tiny/valid', transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953214e8",
   "metadata": {},
   "source": [
    "#### Architektura modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e3376ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Model, self).__init__()\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1), \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1), \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.block_3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1), \n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.block_3(x)\n",
    "        x = self.global_avg_pool(x)  # teraz 256 x 1 x 1\n",
    "        logits = self.classifier(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e969b99e",
   "metadata": {},
   "source": [
    "#### Trening modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119e366d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1: Train Acc: 10.60% | Val Acc: 16.60% | Train Loss: 2.2883 | Val Loss: 2.2550\n",
      "Epoch 2: Train Acc: 19.93% | Val Acc: 28.20% | Train Loss: 2.2246 | Val Loss: 2.1800\n",
      "Epoch 3: Train Acc: 22.60% | Val Acc: 29.60% | Train Loss: 2.1753 | Val Loss: 2.1284\n",
      "Epoch 4: Train Acc: 25.40% | Val Acc: 29.20% | Train Loss: 2.1269 | Val Loss: 2.0965\n",
      "Epoch 5: Train Acc: 26.20% | Val Acc: 31.40% | Train Loss: 2.0992 | Val Loss: 2.0633\n",
      "Epoch 6: Train Acc: 27.07% | Val Acc: 32.00% | Train Loss: 2.0910 | Val Loss: 2.0534\n",
      "Epoch 7: Train Acc: 28.47% | Val Acc: 34.40% | Train Loss: 2.0596 | Val Loss: 2.0323\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "model = Model(num_classes=10).to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, weight_decay=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# === EARLY STOPPING PARAMETRY ===\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "patience = 7  # liczba epok bez poprawy\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct_train += (preds == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "    train_acc = correct_train / total_train\n",
    "\n",
    "    # === EWALUACJA ===\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_acc = correct / total\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Acc: {train_acc*100:.2f}% | Val Acc: {val_acc*100:.2f}% | \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # === EARLY STOPPING SPRAWDZENIE ===\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        # (opcjonalnie: torch.save(model.state_dict(), 'best_model.pth'))\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1} — validation loss didn't improve for {patience} epochs.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "797211f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   apple_pie       0.35      0.40      0.37        50\n",
      "    bibimbap       0.44      0.72      0.55        50\n",
      "     cannoli       0.42      0.32      0.36        50\n",
      "     edamame       0.92      0.94      0.93        50\n",
      "     falafel       0.39      0.30      0.34        50\n",
      "french_toast       0.65      0.44      0.52        50\n",
      "   ice_cream       0.47      0.38      0.42        50\n",
      "       ramen       0.37      0.56      0.45        50\n",
      "       sushi       0.25      0.36      0.30        50\n",
      "    tiramisu       0.38      0.10      0.16        50\n",
      "\n",
      "    accuracy                           0.45       500\n",
      "   macro avg       0.47      0.45      0.44       500\n",
      "weighted avg       0.47      0.45      0.44       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(all_labels, all_preds)*100:.2f}%')\n",
    "print(classification_report(all_labels, all_preds, target_names=test_dataset.classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
